# Stroom configuration file
# =========================

# For information on the structure of this configuration file see:
# https://www.dropwizard.io/en/latest/manual/configuration.html#logging
# For information on the logback logFormat strings see:
# http://logback.qos.ch/manual/layouts.html

# This section is the DropWizard configuration for Stroom

server:
  applicationContextPath: ${APPLICATION_CONTEXT_PATH:- /}
  adminContextPath: ${ADMIN_CONTEXT_PATH:- /stroomAdmin}
  applicationConnectors:
    - type: http
      port: ${STROOM_APP_PORT:-8080}
  adminConnectors:
    - type: http
      port: ${STROOM_ADMIN_PORT:-8081}

  requestLog:
    appenders:
      # Log appender for the web server request logging
    - type: file
      currentLogFilename: logs/access/access.log
      threshold: ALL
      queueSize: 256
      discardingThreshold: 0
      archive: true
      # Rolled and gzipped every minute
      archivedLogFilenamePattern: logs/access/access-%d{yyyy-MM-dd'T'HH:mm}.log.gz
      archivedFileCount: 100
      timeZone: UTC

logging:
  level: ${STROOM_LOGGING_LEVEL:- WARN}
  loggers:
    stroom: INFO
    io.dropwizard: INFO
    org.eclipse.jetty: INFO
    org.glassfish: INFO
    org.glassfish.jersey: INFO
    # Comment this out if you want logging of the REST request/responses
    # NOT recommended for production environments as it is very verbose
    org.glassfish.jersey.logging.LoggingFeature: "OFF"
    #    org.glassfish.jersey.server.ServerRuntime.Responder: INFO
    #    org.glassfish.jersey.server.validation.internal.ValidationExceptionMapper: FINER
    org.flywaydb: INFO
    # Logger and appender for audit logs
    "event-logger":
      level: INFO
      additive: false
      appenders:
        - type: file
          currentLogFilename: logs/events/event.log
          threshold: ALL
          queueSize: 256
          discardingThreshold: 0
          archive: true
          # Rolled every minute
          archivedLogFilenamePattern: logs/events/event-%d{yyyy-MM-dd'T'HH:mm}.log
          archivedFileCount: 100
          timeZone: UTC
          logFormat: "%msg%n"
    # Logger and appender for the flyway DB migration SQL output
    org.flywaydb.core.internal.sqlscript:
      level: DEBUG
      additive: false
      appenders:
        - type: file
          currentLogFilename: logs/migration.log
          threshold: ALL
          queueSize: 256
          discardingThreshold: 0
          archive: true
          # Rolled every day
          archivedLogFilenamePattern: logs/migration-%d{yyyy-MM-dd}.log
          archivedFileCount: 10
          timeZone: UTC
          logFormat: "%-6level [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%t] %logger - %X{code} %msg %n"

  appenders:

    # stdout for docker
    # Comment out for non-dockered environments
  - type: console
    # Multi-coloured log format for console output
    logFormat: "%highlight(%-6level) [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%green(%t)] %cyan(%logger) - %X{code} %msg %n"
    timeZone: UTC

    # Minute rolled files for stroom/datafeed, will be curl'd/deleted by stroom-log-sender
  - type: file
    currentLogFilename: logs/app/app.log
    threshold: ALL
    queueSize: 256
    discardingThreshold: 0
    archive: true
    # Rolled and gzipped every minute
    archivedLogFilenamePattern: logs/app/app-%d{yyyy-MM-dd'T'HH:mm}.log.gz
    # One week using minute files
    archivedFileCount: 10080
    timeZone: UTC
    logFormat: "%-6level [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%t] %logger - %X{code} %msg %n"

    # Size rolled logs for admins (10x100M), not curl'd to stroom
    # Un-comment for non-dockered environments
    #  - type: file
    #    currentLogFilename: logs/app.log
    #    threshold: ALL
    #    queueSize: 256
    #    discardingThreshold: 0
    #    archive: true
    #    archivedLogFilenamePattern: logs/app-%i.log
    #    archivedFileCount: 10
    #    maxFileSize: "100MB"
    #    timeZone: UTC
    #    logFormat: "%-6level [%d{\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\",UTC}] [%t] %logger - %X{code} %msg %n"


# This section contains the Stroom configuration properties
# For mor information see:
# https://gchq.github.io/stroom-docs/user-guide/properties.html

appConfig:
  commonDbDetails:
    connection:
      jdbcDriverClassName: ${STROOM_JDBC_DRIVER_CLASS_NAME:-com.mysql.cj.jdbc.Driver}
      jdbcDriverUrl: ${STROOM_JDBC_DRIVER_URL:-jdbc:mysql://localhost:3307/stroom?useUnicode=yes&characterEncoding=UTF-8}
      jdbcDriverUsername: ${STROOM_JDBC_DRIVER_USERNAME:-stroomuser}
      jdbcDriverPassword: ${STROOM_JDBC_DRIVER_PASSWORD:-stroompassword1}
  contentPackImport:
    enabled: ${STROOM_CONTENT_PACK_IMPORT_ENABLED:-false}
  job:
    enabled: true
    enableDistributedJobsOnBootstrap: ${STROOM_DISTRIBUTED_JOBS_ENABLED_ON_BOOTSTRAP:-true}
    executionInterval: "10s"
  node:
    # The name for the node, should be unique to each node in the cluster
    name: ${STROOM_NODE:-node1a}
  # The address of the this node for inter-node communication
  nodeUri:
    hostname: ${STROOM_HOST:-localhost}
  path:
    temp: "/tmp/stroom"
  pipeline:
    referenceData:
      localDir: ${STROOM_REF_DATA_STORE_DIR:-/tmp/stroom/refDataOffHeapStore}
  proxyAggregation:
    proxyDir: ${STROOM_PROXY_DIR:-/tmp/stroom/proxy}
  # The public address for stroom, typically the public address of nginx
  publicUri:
    hostname: ${API_GATEWAY_HOST:-localhost}
    port: ${API_GATEWAY_PORT:-443}
  security:
    authentication:
      preventLogin: false
    identity:
      useDefaultOpenIdCredentials: ${USE_DEFAULT_OPEN_ID_CREDENTIALS:-true}
  serviceDiscovery:
    enabled: ${STROOM_SERVICE_DISCOVERY_ENABLED:-false}
    zookeeperUrl: ${STROOM_SERVICE_DISCOVERY_ZOOKEEPER_URL:-localhost:2181}
  statistics:
    hbase:
      kafkaConfigUuid:
    internal:
      enabledStoreTypes: ${STROOM_ENABLED_STAT_STORE_TYPES:-[ "StatisticStore" ]}
  volumes:
    createDefaultIndexVolumesOnStart: ${STROOM_CREATE_DEFAULT_INDEX_VOLUMES:-false}
    defaultIndexVolumeGroupPaths: ${STROOM_DEFAULT_INDEX_VOLUME_PATHS:-volumes/defaultIndexVolume}
    defaultIndexVolumeGroupNodes: ${STROOM_DEFAULT_INDEX_VOLUME_NODES:-node1a}
  data:
    filesystemVolume:
      createDefaultStreamVolumesOnStart: ${STROOM_CREATE_DEFAULT_STREAM_VOLUMES:-false}
      defaultStreamVolumePaths: ${STROOM_DEFAULT_STREAM_VOLUME_PATHS:-volumes/defaultStreamVolume}
